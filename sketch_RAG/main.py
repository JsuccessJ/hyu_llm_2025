import os
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_community.llms import HuggingFacePipeline
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain.embeddings import HuggingFaceEmbeddings
from dotenv import load_dotenv
from huggingface_hub import login
from project_llm_scentbot.sketch_RAG.prompt_loader import *

load_dotenv()
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")
login(token=hf_token)
    
# LLaMA 3 ëª¨ë¸ & í† í¬ë‚˜ì´ì € ë¡œë”©
MODEL_ID = "meta-llama/Llama-3.2-3B-Instruct"  
print("ëª¨ë¸ ë¡œë”© ì¤‘...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_auth_token=hf_token)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    device_map="auto",
    torch_dtype="auto",
    use_auth_token=hf_token,
)
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

# í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ êµ¬ì„±
llm_pipeline = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=512,
    temperature=0.7,
    do_sample=True,
)

# LangChainìš© ë˜í¼
llm = HuggingFacePipeline(pipeline=llm_pipeline)

# FAISS ë²¡í„° DB ë¡œë”© ---
EMBED_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
embed_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL_NAME)

print("FAISS ë²¡í„° DB ë¡œë”© ì¤‘...")
vector_store = FAISS.load_local("./perfume_faiss_index", embed_model,allow_dangerous_deserialization=True)  # ê²½ë¡œ ë§ê²Œ ìˆ˜ì •
print("ë²¡í„° DB ë¡œë”© ì™„ë£Œ")

# Retriever ìƒì„±
retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 3})

# í”„ë¡¬í”„íŠ¸ ë¡œë”©
prompts = load_prompts_from_yaml("./prompts.yaml")
selected_prompt = prompts["basic_prompt"]  

# RAG RetrievalQA ì²´ì¸ êµ¬ì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True,
    chain_type_kwargs={"prompt": selected_prompt}
)
# ì‚¬ìš©ì ì§ˆì˜ í•¨ìˆ˜
def ask(query: str):
    result = qa_chain({"query": query})
    print("ğŸ’¬ ì§ˆë¬¸:", query)
    print("ğŸ§  ë‹µë³€:", result['result'])
    print("\nğŸ“š ì°¸ì¡° ë¬¸ì„œ:")
    for doc in result["source_documents"]:
        brand = doc.metadata.get("brand_name", "ì•Œ ìˆ˜ ì—†ìŒ")
        rating = doc.metadata.get("rating_value", "?")
        print(f"- ë¸Œëœë“œ: {brand} | í‰ì : {rating}")

if __name__ == "__main__":
    print("=== LLaMA 3 + RAG QA ì‹œìŠ¤í…œ ===")
    while True:
        query = input("ì§ˆë¬¸ ì…ë ¥ (ì¢…ë£ŒëŠ” exit): ")
        if query.lower() in ("exit", "quit"):
            print("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
            break
        ask(query)
