# LangChain ê¸°ë°˜ Graph-RAG í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ (Pydantic í˜¸í™˜ì„± ìˆ˜ì •)
# BaseTool ìƒì† ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¼ë°˜ í´ë˜ìŠ¤ë¡œ ì¬êµ¬ì„±

import os
import torch
import numpy as np
from typing import List, Dict, Optional, Tuple, Any
from collections import Counter
import json

# LangChain ê´€ë ¨ ì„í¬íŠ¸
from langchain_community.vectorstores import Neo4jVector
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_community.graphs import Neo4jGraph
from langchain.memory import ConversationBufferMemory

# ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬
from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, pipeline
from peft import PeftModel
from neo4j import GraphDatabase
from konlpy.tag import Okt
from dotenv import load_dotenv

load_dotenv()


class PerfumeGraphSearcher:
    """
    ğŸ” í–¥ìˆ˜ ê·¸ë˜í”„ ê²€ìƒ‰ ì—”ì§„
    
    ê¸°ì¡´ Neo4jRetrieval í´ë˜ìŠ¤ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ë…ë¦½ í´ë˜ìŠ¤ë¡œ êµ¬í˜„
    - í‚¤ì›Œë“œ ì¶”ì¶œ ë° Seed Node ì„ íƒ
    - ê·¸ë˜í”„ í™•ì¥ ë° Accord ì²´ì¸ íƒìƒ‰  
    - í–¥ìˆ˜ ì ìˆ˜ ê³„ì‚° ë° ë­í‚¹
    """
    
    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str, database: str = None):
        # Neo4j ì—°ê²°
        self.driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        self.database = database or "neo4j"  # ê¸°ë³¸ê°’ì€ neo4j
        
        # ë¼ë²¨ ì„¤ì • (ê¸°ë³¸ ë¼ë²¨ ì‚¬ìš©)
        self.labels = {
            'Perfume': 'Perfume',
            'Brand': 'Brand',
            'Target': 'Target',
            'Accord': 'Accord'
        }
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (BGE-M3)
        self.model_name = "BAAI/bge-m3"
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModel.from_pretrained(self.model_name)
        
        # ì„ë² ë”© ìºì‹œ ë° í˜•íƒœì†Œ ë¶„ì„ê¸°
        self.embedding_cache = {}
        self.okt = Okt()
        
        print("âœ… PerfumeGraphSearcher ì´ˆê¸°í™” ì™„ë£Œ")
    
    def search(self, query: str) -> str:
        """
        ğŸ¯ ë©”ì¸ ê²€ìƒ‰ ì‹¤í–‰ í•¨ìˆ˜
        
        1. í‚¤ì›Œë“œ ì¶”ì¶œ â†’ 2. Seed Node ì„ íƒ â†’ 3. ê·¸ë˜í”„ í™•ì¥ â†’ 4. ì ìˆ˜ ê³„ì‚°
        """
        try:
            print(f"\nğŸ” Graph-RAG ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            # 1ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(query)
            print(f"ğŸ“ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
            
            # 2ë‹¨ê³„: Seed Node ì„ íƒ
            seed_nodes = self._get_seed_nodes(keywords)
            print(f"ğŸŒ± Seed Nodes: {seed_nodes}")
            
            if not any(seed_nodes.values()):
                return "ê´€ë ¨ëœ í–¥ìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # 3ë‹¨ê³„: ê·¸ë˜í”„ í™•ì¥
            expanded_graph = self._expand_graph(seed_nodes)
            print(f"ğŸŒ ê·¸ë˜í”„ í™•ì¥: {len(expanded_graph['paths'])}ê°œ ê²½ë¡œ, {len(expanded_graph['perfumes'])}ê°œ í–¥ìˆ˜")
            
            # 4ë‹¨ê³„: í–¥ìˆ˜ ì ìˆ˜ ê³„ì‚°
            perfume_rankings = self._calculate_perfume_scores(expanded_graph, seed_nodes)
            
            # 5ë‹¨ê³„: ê²°ê³¼ í¬ë§·íŒ…
            result = self._format_results(query, seed_nodes, expanded_graph, perfume_rankings)
            
            return result
            
        except Exception as e:
            error_msg = f"âŒ Graph-RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(error_msg)
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í–¥ìˆ˜ ê²€ìƒ‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def _extract_keywords(self, text: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ + ë¸Œëœë“œ/í–¥ì¡°ëª… ë§¤í•‘ (ê°œì„ ëœ ë²„ì „)"""
        stopwords = ['ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ë˜ëŠ”', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 
                    'ê·¸ë˜ì„œ','ë•Œë¬¸ì—', 'ìœ„í•´', 'ëŒ€í•´', 'ê´€ë ¨', 'ë”°ë¼ì„œ', 'ê·¸ëŸ¬ë‚˜', 'ë˜í•œ', 
                    'ì¶”ì²œ','í•˜ë‹¤','í•´ì£¼ë‹¤','ë‚˜', 'ìš©ì´','ì–´ìš¸ë¦¬ë‹¤','ì•Œë‹¤', 'ë­', 'ì¢‹ë‹¤', 
                    'í–¥ìˆ˜','ê³„ì—´','í–¥', 'ìˆë‹¤','ì°¾ë‹¤', 'ê²Œ', 'ì–´ë–»ë‹¤']
        
        # ë¸Œëœë“œëª… í•œê¸€â†”ì˜ë¬¸ ë§¤í•‘ (ë” ë§ì€ ë³€í˜• í¬í•¨)
        brand_mapping = {
            # ê¸°ë³¸ ë¸Œëœë“œëª…
            'ìƒ¤ë„¬': 'Chanel', 'í†°í¬ë“œ': 'Tom Ford', 'ë””ì˜¬': 'Dior',
            'êµ¬ì°Œ': 'Gucci', 'ë²„ë²„ë¦¬': 'Burberry', 'ì—ë¥´ë©”ìŠ¤': 'Hermes',
            'ì¡°ë§ë¡ ': 'Jo Malone', 'ë‘ì½¤': 'Lancome', 'ì´ë¸Œìƒë¡œë‘': 'Yves Saint Laurent',
            'ì§€ë°©ì‹œ': 'Givenchy', 'í”„ë¼ë‹¤': 'Prada', 'ì•„ë¥´ë§ˆë‹ˆ': 'Armani',
            # ë¶„ë¦¬ëœ í˜•íƒœë„ ë§¤í•‘
            'í†° í¬ë“œ': 'Tom Ford', 'tom ford': 'Tom Ford', 'tomford': 'Tom Ford',
            'ì¡° ë§ë¡ ': 'Jo Malone', 'jo malone': 'Jo Malone', 'jomalone': 'Jo Malone',
            'ì´ë¸Œ ìƒë¡œë‘': 'Yves Saint Laurent', 'ysl': 'Yves Saint Laurent'
        }
        
        # í–¥ì¡°ëª… í•œê¸€â†”ì˜ë¬¸ ë§¤í•‘ (ë” ë§ì€ ë³€í˜• í¬í•¨)
        accord_mapping = {
            'ìš°ë””': 'woody', 'í”Œë¡œëŸ´': 'floral', 'ì‹œíŠ¸ëŸ¬ìŠ¤': 'citrus',
            'ì˜¤ë¦¬ì—”íƒˆ': 'oriental', 'í”„ë ˆì‹œ': 'fresh', 'ìŠ¤íŒŒì´ì‹œ': 'spicy',
            'ë°”ë‹ë¼': 'vanilla', 'ë¨¸ìŠ¤í¬': 'musk', 'ì•°ë²„': 'amber', 'ë¡œì¦ˆ': 'rose',
            # ì˜ë¬¸ë„ ì¶”ê°€
            'woody': 'woody', 'floral': 'floral', 'citrus': 'citrus',
            'oriental': 'oriental', 'fresh': 'fresh', 'spicy': 'spicy'
        }
        
        # íƒ€ê²Ÿ ë§¤í•‘ ì¶”ê°€
        target_mapping = {
            'ë‚¨ì': 'for men', 'ë‚¨ì„±': 'for men', 'ë‚¨': 'for men',
            'ì—¬ì': 'for women', 'ì—¬ì„±': 'for women', 'ì—¬': 'for women',
            'ìœ ë‹ˆì„¹ìŠ¤': 'unisex', 'ë‚¨ë…€ê³µìš©': 'unisex'
        }
        
        # 1ë‹¨ê³„: ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ë¸Œëœë“œëª… ì°¾ê¸°
        text_lower = text.lower()
        found_brands = []
        for brand_kr, brand_en in brand_mapping.items():
            if brand_kr in text:
                found_brands.extend([brand_kr, brand_en])
        
        # 2ë‹¨ê³„: í˜•íƒœì†Œ ë¶„ì„
        tokens = self.okt.pos(text, stem=True)
        keywords = [word for word, pos in tokens 
                   if pos in ['Noun', 'Verb', 'Adjective'] 
                   and word not in stopwords 
                   and len(word) > 1]  # 1ê¸€ì ë‹¨ì–´ ì œì™¸
        
        # 3ë‹¨ê³„: ë¶„ë¦¬ëœ ë¸Œëœë“œëª… ì¬ì¡°í•© ì‹œë„
        reconstructed_brands = []
        if 'í†°' in keywords and 'í¬ë“œ' in keywords:
            reconstructed_brands.append('í†°í¬ë“œ')
        if 'ì¡°' in keywords and 'ë§ë¡ ' in keywords:
            reconstructed_brands.append('ì¡°ë§ë¡ ')
        if 'ì´ë¸Œ' in keywords and ('ìƒë¡œë‘' in keywords or 'ë¡œë‘' in keywords):
            reconstructed_brands.append('ì´ë¸Œìƒë¡œë‘')
        
        # 4ë‹¨ê³„: ë§¤í•‘ ì ìš©
        mapped_keywords = []
        
        # ì›ë³¸ í‚¤ì›Œë“œ ì¶”ê°€
        mapped_keywords.extend(keywords)
        
        # ì°¾ì€ ë¸Œëœë“œëª… ì¶”ê°€
        mapped_keywords.extend(found_brands)
        
        # ì¬ì¡°í•©ëœ ë¸Œëœë“œëª… ì¶”ê°€
        mapped_keywords.extend(reconstructed_brands)
        
        # ë§¤í•‘ ì ìš©
        for keyword in keywords + reconstructed_brands:
            if keyword in brand_mapping:
                mapped_keywords.append(brand_mapping[keyword])
            if keyword in accord_mapping:
                mapped_keywords.append(accord_mapping[keyword])
            if keyword in target_mapping:
                mapped_keywords.append(target_mapping[keyword])
        
        # ì¤‘ë³µ ì œê±° ë° ë””ë²„ê¹… ì •ë³´
        final_keywords = list(set(mapped_keywords))
        print(f"ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ê³¼ì •:")
        print(f"   ì›ë³¸ í…ìŠ¤íŠ¸: {text}")
        print(f"   í˜•íƒœì†Œ ë¶„ì„: {keywords}")
        print(f"   ì¬ì¡°í•© ë¸Œëœë“œ: {reconstructed_brands}")
        print(f"   ìµœì¢… í‚¤ì›Œë“œ: {final_keywords}")
        
        return final_keywords

    def _get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ìºì‹œ í™œìš©)"""
        if text in self.embedding_cache:
            return self.embedding_cache[text]
            
        inputs = self.tokenizer(text, return_tensors="pt", padding=True, 
                               truncation=True, max_length=512)
        with torch.no_grad():
            outputs = self.model(**inputs)
        embeddings = outputs.last_hidden_state.mean(dim=1)
        embedding = embeddings[0].numpy().tolist()
        
        self.embedding_cache[text] = embedding
        return embedding

    def _cosine_similarity(self, emb1: List[float], emb2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        emb1, emb2 = np.array(emb1), np.array(emb2)
        return float(np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2)))

    def _get_seed_nodes(self, keywords: List[str]) -> Dict[str, List[str]]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ Seed Node ì„ íƒ (ê°œì„ ëœ ì„ê³„ê°’)"""
        seed_nodes = {'Brand': [], 'Target': [], 'Accord': []}
        
        # ë¼ë²¨ë³„ ë‹¤ë¥¸ ì„ê³„ê°’ ì‚¬ìš©
        thresholds = {
            'Brand': 0.7,   # ë¸Œëœë“œëŠ” ì¡°ê¸ˆ ë” ê´€ëŒ€í•˜ê²Œ
            'Target': 0.75, # íƒ€ê²Ÿì€ ì¤‘ê°„
            'Accord': 0.8   # í–¥ì¡°ëŠ” ì—„ê²©í•˜ê²Œ
        }
        
        for label in ['Brand', 'Target', 'Accord']:
            threshold = thresholds[label]
            nodes = self._get_all_nodes_embeddings(label)
            
            filtered_seeds = []
            keyword_matches = []  # ë””ë²„ê¹…ìš©
            
            for keyword in keywords:
                kw_emb = self._get_embedding(keyword)
                best_match = None
                best_similarity = 0
                
                for node in nodes:
                    similarity = self._cosine_similarity(kw_emb, node['embedding'])
                    if similarity >= threshold and node['name'] not in filtered_seeds:
                        filtered_seeds.append(node['name'])
                        keyword_matches.append(f"{keyword} â†’ {node['name']} ({similarity:.3f})")
                    
                    # ìµœê³  ìœ ì‚¬ë„ ì¶”ì  (ë””ë²„ê¹…ìš©)
                    if similarity > best_similarity:
                        best_similarity = similarity
                        best_match = node['name']
                
                # ì„ê³„ê°’ì„ ë„˜ì§€ ëª»í•œ ê²½ìš°ë„ ë¡œê¹…
                if best_match and best_similarity < threshold:
                    keyword_matches.append(f"{keyword} â†’ {best_match} ({best_similarity:.3f}) [ì„ê³„ê°’ ë¯¸ë‹¬]")
            
            seed_nodes[label] = filtered_seeds[:5]  # ìµœëŒ€ 5ê°œë¡œ ì¦ê°€
            
            # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
            print(f"ğŸ¯ {label} ë§¤ì¹­ (ì„ê³„ê°’: {threshold}):")
            for match in keyword_matches:
                print(f"   {match}")
            print(f"   ìµœì¢… ì„ íƒ: {seed_nodes[label]}")
        
        return seed_nodes

    def _get_all_nodes_embeddings(self, label: str) -> List[Dict]:
        """íŠ¹ì • ë¼ë²¨ì˜ ëª¨ë“  ë…¸ë“œ ì„ë² ë”© ì¡°íšŒ (V2 ë¼ë²¨ ì§€ì›)"""
        actual_label = self.labels.get(label, label)  # ë™ì  ë¼ë²¨ ì‚¬ìš©
        with self.driver.session(database=self.database) as session:
            query = f"""
            MATCH (n:{actual_label})
            WHERE n.embedding IS NOT NULL
            RETURN n.name as name, n.embedding as embedding
            """
            return [dict(record) for record in session.run(query)]

    def _expand_graph(self, seed_nodes: Dict[str, List[str]]) -> Dict:
        """ê·¸ë˜í”„ í™•ì¥ ë° Accord ì²´ì¸ íƒìƒ‰ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
        expanded_graph = {
            'paths': [],
            'perfumes': set(),
            'seed_connections': {},
            'accord_chains': []
        }
        
        with self.driver.session(database=self.database) as session:
            # Brand â†’ Perfume â†’ Accord ê²½ë¡œ
            for brand_seed in seed_nodes['Brand']:
                query = f"""
                    MATCH (seed_brand:{self.labels['Brand']} {{name: $brand_seed}})
                    MATCH (seed_brand)<-[:HAS_BRAND]-(p:{self.labels['Perfume']})-[ha:HAS_ACCORD]->(a:{self.labels['Accord']})
                    OPTIONAL MATCH (p)-[:FOR_TARGET]->(t:{self.labels['Target']})
                    RETURN 'Brandâ†’Perfumeâ†’Accord' as path_type,
                           seed_brand.name as seed_node,
                           p.name as perfume,
                           a.name as end_node,
                           t.name as target,
                           ha.strength as strength,
                           p.rating_value as rating,
                           p.review_count as reviews
                """
                results = session.run(query, brand_seed=brand_seed)
                
                for record in results:
                    expanded_graph['paths'].append({
                        'path_type': record['path_type'],
                        'seed_node': record['seed_node'],
                        'seed_type': 'Brand',
                        'perfume': record['perfume'],
                        'end_node': record['end_node'],
                        'end_type': 'Accord',
                        'target': record['target'],
                        'strength': record['strength'],
                        'rating': record['rating'],
                        'reviews': record['reviews']
                    })
                    expanded_graph['perfumes'].add(record['perfume'])
            
            # Target â†’ Perfume â†’ Accord ê²½ë¡œ  
            for target_seed in seed_nodes['Target']:
                query = f"""
                    MATCH (seed_target:{self.labels['Target']} {{name: $target_seed}})
                    MATCH (seed_target)<-[:FOR_TARGET]-(p:{self.labels['Perfume']})-[ha:HAS_ACCORD]->(a:{self.labels['Accord']})
                    OPTIONAL MATCH (p)-[:HAS_BRAND]->(b:{self.labels['Brand']})
                    RETURN 'Targetâ†’Perfumeâ†’Accord' as path_type,
                           seed_target.name as seed_node,
                           p.name as perfume,
                           a.name as end_node,
                           b.name as brand,
                           ha.strength as strength,
                           p.rating_value as rating,
                           p.review_count as reviews
                """
                results = session.run(query, target_seed=target_seed)
                
                for record in results:
                    expanded_graph['paths'].append({
                        'path_type': record['path_type'],
                        'seed_node': record['seed_node'],
                        'seed_type': 'Target',
                        'perfume': record['perfume'],
                        'end_node': record['end_node'],
                        'end_type': 'Accord',
                        'brand': record['brand'],
                        'strength': record['strength'],
                        'rating': record['rating'],
                        'reviews': record['reviews']
                    })
                    expanded_graph['perfumes'].add(record['perfume'])
            
            # Accord â†’ Perfume â†’ Brand ê²½ë¡œ
            for accord_seed in seed_nodes['Accord']:
                query = f"""
                    MATCH (seed_accord:{self.labels['Accord']} {{name: $accord_seed}})
                    MATCH (seed_accord)<-[ha:HAS_ACCORD]-(p:{self.labels['Perfume']})-[:HAS_BRAND]->(b:{self.labels['Brand']})
                    OPTIONAL MATCH (p)-[:FOR_TARGET]->(t:{self.labels['Target']})
                    RETURN 'Accordâ†’Perfumeâ†’Brand' as path_type,
                           seed_accord.name as seed_node,
                           p.name as perfume,
                           b.name as end_node,
                           t.name as target,
                           ha.strength as strength,
                           p.rating_value as rating,
                           p.review_count as reviews
                """
                results = session.run(query, accord_seed=accord_seed)
                
                for record in results:
                    expanded_graph['paths'].append({
                        'path_type': record['path_type'],
                        'seed_node': record['seed_node'],
                        'seed_type': 'Accord',
                        'perfume': record['perfume'],
                        'end_node': record['end_node'],
                        'end_type': 'Brand',
                        'target': record['target'],
                        'strength': record['strength'],
                        'rating': record['rating'],
                        'reviews': record['reviews']
                    })
                    expanded_graph['perfumes'].add(record['perfume'])
            
            # ğŸ”— Accord ì²´ì¸ íƒìƒ‰ (3-í™‰)
            accord_chains = []
            all_seed_accords = seed_nodes.get('Accord', [])
            
            for seed_accord in all_seed_accords:
                query = f"""
                    MATCH path = (a1:{self.labels['Accord']})<-[:HAS_ACCORD]-(p1:{self.labels['Perfume']})-[:HAS_ACCORD]->(a2:{self.labels['Accord']})
                                <-[:HAS_ACCORD]-(p2:{self.labels['Perfume']})-[:HAS_ACCORD]->(a3:{self.labels['Accord']})
                    WHERE (a1.name = $seed_accord OR a2.name = $seed_accord OR a3.name = $seed_accord)
                    AND a1 <> a2 AND a2 <> a3 AND a1 <> a3
                    RETURN a1.name as start_accord, a2.name as middle_accord, 
                           a3.name as end_accord, p1.name as perfume1, p2.name as perfume2
                    LIMIT 5
                """
                chain_results = session.run(query, seed_accord=seed_accord)
                
                chains = [dict(record) for record in chain_results]
                accord_chains.extend(chains)
            
            expanded_graph['accord_chains'] = accord_chains
        
        return expanded_graph

    def _calculate_perfume_scores(self, expanded_graph: Dict, seed_nodes: Dict) -> List[Dict]:
        """í–¥ìˆ˜ ì ìˆ˜ ê³„ì‚° (ê¸°ë³¸ì ìˆ˜ + ì²´ì¸ë³´ë„ˆìŠ¤)"""
        perfume_scores = {}
        
        # 1. ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° (ê²½ë¡œ ê°œìˆ˜)
        for path in expanded_graph['paths']:
            perfume = path['perfume']
            if perfume not in perfume_scores:
                perfume_scores[perfume] = {
                    'base_score': 0,
                    'chain_bonus': 0,
                    'rating': 0,
                    'paths': []
                }
            
            perfume_scores[perfume]['base_score'] += 1
            perfume_scores[perfume]['paths'].append(path)
            
            if path.get('rating'):
                try:
                    perfume_scores[perfume]['rating'] = float(path['rating'])
                except:
                    pass
        
        # 2. ì²´ì¸ ë³´ë„ˆìŠ¤ ê³„ì‚°
        if expanded_graph.get('accord_chains'):
            chain_bonus = self._calculate_chain_bonus(
                expanded_graph['accord_chains'], 
                seed_nodes
            )
            
            for perfume, bonus in chain_bonus.items():
                if perfume in perfume_scores:
                    perfume_scores[perfume]['chain_bonus'] = bonus
                else:
                    perfume_scores[perfume] = {
                        'base_score': 0,
                        'chain_bonus': bonus,
                        'rating': 0,
                        'paths': []
                    }
        
        # 3. ìµœì¢… ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        ranked_perfumes = []
        for perfume, scores in perfume_scores.items():
            final_score = scores['base_score'] + scores['chain_bonus']
            ranked_perfumes.append({
                'perfume': perfume,
                'final_score': final_score,
                'base_score': scores['base_score'],
                'chain_bonus': scores['chain_bonus'],
                'avg_rating': scores['rating'],
                'path_count': len(scores['paths']),
                'paths': scores['paths']
            })
        
        # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        ranked_perfumes.sort(key=lambda x: (x['final_score'], x['avg_rating']), reverse=True)
        
        return ranked_perfumes[:5]  # Top-5 ë°˜í™˜

    def _calculate_chain_bonus(self, accord_chains: List[Dict], seed_nodes: Dict) -> Dict:
        """ì²´ì¸ ë³´ë„ˆìŠ¤ ê³„ì‚° (+3ì ì”©)"""
        chain_bonus = {}
        seed_brands = set(seed_nodes.get('Brand', []))
        seed_targets = set(seed_nodes.get('Target', []))
        
        for chain in accord_chains:
            for perfume in [chain['perfume1'], chain['perfume2']]:
                if self._is_chain_perfume_relevant(perfume, seed_brands, seed_targets):
                    if perfume not in chain_bonus:
                        chain_bonus[perfume] = 0
                    chain_bonus[perfume] += 3
        
        return chain_bonus

    def _is_chain_perfume_relevant(self, perfume_name: str, seed_brands: set, seed_targets: set) -> bool:
        """ì²´ì¸ í–¥ìˆ˜ì˜ ê´€ë ¨ì„± ê²€ì¦"""
        if not seed_brands and not seed_targets:
            return True
        
        with self.driver.session(database=self.database) as session:
            query = f"""
                MATCH (p:{self.labels['Perfume']} {{name: $perfume_name}})
                OPTIONAL MATCH (p)-[:HAS_BRAND]->(b:{self.labels['Brand']})
                OPTIONAL MATCH (p)-[:FOR_TARGET]->(t:{self.labels['Target']})
                RETURN b.name as brand, t.name as target
            """
            result = session.run(query, perfume_name=perfume_name).single()
            
            if not result:
                return False
            
            perfume_brand = result['brand']
            perfume_target = result['target']
            
            brand_match = not seed_brands or perfume_brand in seed_brands
            target_match = not seed_targets or perfume_target in seed_targets
            
            return brand_match or target_match

    def _format_results(self, query: str, seed_nodes: Dict, expanded_graph: Dict, perfume_rankings: List[Dict]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ í¬ë§·íŒ… (í†µí•©ëœ í˜•íƒœ)"""
        if not perfume_rankings:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # í–¥ìˆ˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        perfume_names = [p['perfume'] for p in perfume_rankings]
        detailed_perfumes = self._get_detailed_perfume_info(perfume_names)
        
        result = f"""ğŸ” ì‚¬ìš©ì ì§ˆë¬¸: {query}

ğŸ¯ ì¶”ì²œ í–¥ìˆ˜ TOP-{len(perfume_rankings)} (ìƒì„¸ ì •ë³´ í¬í•¨):
"""
        
        # ë­í‚¹ê³¼ ìƒì„¸ ì •ë³´ë¥¼ í•˜ë‚˜ë¡œ í†µí•©
        for i, perfume_data in enumerate(perfume_rankings, 1):
            perfume_name = perfume_data['perfume']
            
            # ìƒì„¸ ì •ë³´ ë§¤ì¹­
            detail = next((p for p in detailed_perfumes if p['name'] == perfume_name), {})
            
            result += f"""{i}. {perfume_name} (ìµœì¢…ì ìˆ˜: {perfume_data['final_score']})
   ğŸ·ï¸ ë¸Œëœë“œ: {detail.get('brand', '-')}
   ğŸ‘¥ íƒ€ê²Ÿ: {detail.get('target', '-')}
   â­ í‰ì : {detail.get('rating', '-')} ({detail.get('reviews', '-')}ë¦¬ë·°)
   ğŸµ ì£¼ìš”í–¥ì¡°: {detail.get('top_accords', '-')}

"""
        
        return result

    def _get_detailed_perfume_info(self, perfume_names: List[str]) -> List[Dict]:
        """ì„ íƒëœ í–¥ìˆ˜ë“¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì¡°íšŒ"""
        if not perfume_names:
            return []
            
        with self.driver.session(database=self.database) as session:
            query = f"""
            MATCH (p:{self.labels['Perfume']})
            WHERE p.name IN $names
            OPTIONAL MATCH (p)-[ha:HAS_ACCORD]->(a:{self.labels['Accord']})
            OPTIONAL MATCH (p)-[:HAS_BRAND]->(b:{self.labels['Brand']})
            OPTIONAL MATCH (p)-[:FOR_TARGET]->(t:{self.labels['Target']})
            RETURN p.name as name, b.name as brand, t.name as target, 
                   collect(DISTINCT {{accord: a.name, strength: ha.strength}}) as accords, 
                   p.rating_value as rating, p.review_count as reviews
            """
            results = [dict(record) for record in session.run(query, names=perfume_names)]
        
        detailed_info = []
        for p in results:
            # í–¥ì¡° ì •ë³´ ì •ë¦¬
            accord_strengths = [
                (a['accord'], float(str(a['strength']).replace('%',''))) 
                for a in p.get('accords', []) if a['accord'] and a['strength'] is not None
            ]
            accord_strengths.sort(key=lambda x: x[1], reverse=True)
            
            seen = set()
            sorted_accords = []
            for name, strength in accord_strengths:
                if name not in seen:
                    sorted_accords.append(f"{name}({strength:.2f}%)")
                    seen.add(name)
            
            detailed_info.append({
                'name': p['name'],
                'brand': p.get('brand', '-'),
                'target': p.get('target', '-'),
                'rating': p.get('rating', '-'),
                'reviews': p.get('reviews', '-'),
                'top_accords': ', '.join(sorted_accords[:5]) if sorted_accords else '-'
            })
        
        return detailed_info

    def test_connection(self) -> bool:
        """Neo4j ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            with self.driver.session(database=self.database) as session:
                result = session.run("RETURN 1 as test")
                return result.single()["test"] == 1
        except Exception as e:
            print(f"Neo4j ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self, 'driver'):
            self.driver.close()


class PerfumeLLMChain:
    """
    ğŸ¤– LangChain ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ LLM ì²´ì¸
    
    Graph-RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°›ì•„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì¶”ì²œ ë¬¸ì¥ì„ ìƒì„±
    """
    
    def __init__(self, model_id: str, adapter_path: str, 
                 max_tokens: int = 150, temperature: float = 0.5, top_p: float = 0.7):
        """Llama 3.1 ëª¨ë¸ + LoRA ì–´ëŒ‘í„° ì´ˆê¸°í™”"""
        self.model_id = model_id
        self.adapter_path = adapter_path
        
        # ìƒì„± ì„¤ì • ì €ì¥
        self.max_tokens = max_tokens
        self.temperature = temperature  
        self.top_p = top_p
        
        # LangChain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë” ê°•ë ¥í•œ ì§€ì‹œì‚¬í•­)
        self.prompt_template = PromptTemplate(
            input_variables=["user_query", "search_results"],
            template="""ë‹¹ì‹ ì€ í–¥ìˆ˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ í–¥ìˆ˜ 3ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {user_query}
ê° í–¥ìˆ˜ì— ëŒ€í•´ ì•„ë˜ ë‚´ìš©ì„ í¬í•¨í•´ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”:
1. ë¸Œëœë“œ ì´ë¦„
2. ì£¼ìš” í–¥ ë…¸íŠ¸ (2~3ê°œ)
3. ì–´ìš¸ë¦¬ëŠ” ê³„ì ˆì´ë‚˜ ìƒí™© (ì˜ˆ: ê°€ì„ ë‚¨ì„±ìš©, ë°ì¼ë¦¬ìš©, ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ìë¦¬ ë“±)

ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´:
{search_results}

# ì£¼ì˜ì‚¬í•­
- ê²€ìƒ‰ ê²°ê³¼ì— ìˆëŠ” í–¥ìˆ˜ë§Œ ì„¤ëª…í•˜ì„¸ìš”.

ë‹µë³€:"""
        )
        
        self._initialize_model()
    
    def _initialize_model(self):
        """ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        hf_token = os.getenv('HF_TOKEN')
        
        # Base ëª¨ë¸ ë¡œë“œ
        base_model = AutoModelForCausalLM.from_pretrained(
            self.model_id,
            torch_dtype=torch.float32,
            device_map="auto",
            token=hf_token
        )
        
        # LoRA ì–´ëŒ‘í„° ì ìš©
        model = PeftModel.from_pretrained(base_model, self.adapter_path)
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        tokenizer = AutoTokenizer.from_pretrained(self.model_id, token=hf_token)
        
        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        self.pipeline = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            device_map="auto",
            torch_dtype=torch.float32
        )
        
        print("âœ… PerfumeLLMChain ì´ˆê¸°í™” ì™„ë£Œ")
    
    def generate_recommendation(self, user_query: str, search_results: str) -> str:
        """í–¥ìˆ˜ ì¶”ì²œ í…ìŠ¤íŠ¸ ìƒì„±"""
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.prompt_template.format(
                user_query=user_query,
                search_results=search_results
            )
            
            # í„°ë¯¸ë„ì— LLM ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì¶œë ¥
            print("\n" + "="*80)
            print("ğŸ¤– LLMì— ì…ë ¥ë˜ëŠ” ì‹¤ì œ í”„ë¡¬í”„íŠ¸:")
            print("="*80)
            print(prompt)
            print("="*80)
            print(f"âš™ï¸ ìƒì„± ì„¤ì •: max_tokens={self.max_tokens}, temperature={self.temperature}, top_p={self.top_p}")
            print("="*80)
            
            # LLM ì¶”ë¡  (ì„¤ì •ê°’ ì‚¬ìš©)
            outputs = self.pipeline(
                prompt,
                max_new_tokens=self.max_tokens,
                do_sample=True,
                temperature=self.temperature,
                top_p=self.top_p,
                pad_token_id=self.pipeline.tokenizer.eos_token_id
            )
            
            # ì‘ë‹µ í›„ì²˜ë¦¬
            full_response = outputs[0]["generated_text"]
            final_response = self._extract_generated_response(full_response, prompt)
            
            # í„°ë¯¸ë„ì— LLM ì›ë³¸ ì¶œë ¥ í‘œì‹œ
            print("\n" + "-"*80)
            print("ğŸ¯ LLM ì›ë³¸ ì‘ë‹µ:")
            print("-"*80)
            print(full_response)
            print("-"*80)
            
            # í„°ë¯¸ë„ì— ìµœì¢… ì‘ë‹µ í‘œì‹œ (ì •ì œ ì—†ì´)
            print("\n" + "ğŸŒŸ ìµœì¢… ì‘ë‹µ:")
            print("-"*80)
            print(final_response)
            print("-"*80 + "\n")
            
            return final_response
            
        except Exception as e:
            print(f"âŒ LLM ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¶”ì²œ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _extract_generated_response(self, full_output: str, prompt: str) -> str:
        """ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ ë‹µë³€ë§Œ ì¶”ì¶œ (ì •ì œ ìµœì†Œí™”)"""
        
        # í”„ë¡¬í”„íŠ¸ ì œê±°
        if prompt in full_output:
            response = full_output.replace(prompt, "").strip()
        else:
            response = full_output.strip()
        
        # "ë‹µë³€:" ì´í›„ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        if "ë‹µë³€:" in response:
            response = response.split("ë‹µë³€:", 1)[1].strip()
        
        # ê¸°ë³¸ì ì¸ ì •ë¦¬ë§Œ ìˆ˜í–‰ (ì •ì œ ìµœì†Œí™”)
        if not response or len(response.strip()) < 10:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¶”ì²œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        return response.strip()


class LangChainGraphRAG:
    """
    ğŸš€ LangChain ê¸°ë°˜ í†µí•© Graph-RAG ì‹œìŠ¤í…œ
    
    PerfumeGraphSearcher + PerfumeLLMChainì„ ê²°í•©í•œ ì™„ì „í•œ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ
    """
    
    def __init__(self, 
                 neo4j_uri: str = None, 
                 neo4j_user: str = None, 
                 neo4j_password: str = None,
                 database: str = None,  # ë°ì´í„°ë² ì´ìŠ¤ íŒŒë¼ë¯¸í„° ì¶”ê°€
                 model_id: str = None,
                 adapter_path: str = None,
                 max_tokens: int = 150,
                 temperature: float = 0.5,
                 top_p: float = 0.7):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
        self.neo4j_uri = neo4j_uri or os.getenv('NEO4J_URI')
        self.neo4j_user = neo4j_user or os.getenv('NEO4J_USER')
        self.neo4j_password = neo4j_password or os.getenv('NEO4J_PASSWORD')
        self.model_id = model_id or os.getenv('MODEL_ID')
        self.adapter_path = "/home/shcho95/yjllm/llama3_8b/weight/perfume_llama3_8B_v0"
        
        # êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
        self.graph_searcher = PerfumeGraphSearcher(
            neo4j_uri=self.neo4j_uri, 
            neo4j_user=self.neo4j_user, 
            neo4j_password=self.neo4j_password,
            database=database  # ë°ì´í„°ë² ì´ìŠ¤ íŒŒë¼ë¯¸í„° ì „ë‹¬
        )
        
        self.llm_chain = PerfumeLLMChain(
            self.model_id,
            self.adapter_path,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p
        )
        
        # ë©”ëª¨ë¦¬ (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬)
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        print("âœ… LangChainGraphRAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_recommendation(self, user_query: str, **kwargs) -> dict:
        """
        ğŸ¯ Streamlitìš© ì¶”ì²œ í•¨ìˆ˜ (ë”•ì…”ë„ˆë¦¬ ë°˜í™˜)
        """
        try:
            # kwargsì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ë° ì ìš©
            if 'temperature' in kwargs or 'max_tokens' in kwargs or 'top_p' in kwargs:
                self.update_generation_settings(
                    max_tokens=kwargs.get('max_tokens'),
                    temperature=kwargs.get('temperature'),
                    top_p=kwargs.get('top_p')
                )
            
            response = self.ask(user_query)
            return {
                "response": response,
                "metadata": {
                    "database": getattr(self.graph_searcher, 'database', 'neo4j'),
                    "model_settings": self.get_generation_settings()
                }
            }
        except Exception as e:
            return {
                "response": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "metadata": {"error": True}
            }

    def ask(self, user_query: str) -> str:
        """
        ğŸ¯ ë©”ì¸ ì¶”ì²œ í•¨ìˆ˜
        
        1. Graph-RAG ê²€ìƒ‰ â†’ 2. LLM ìƒì„± â†’ 3. ë©”ëª¨ë¦¬ ì €ì¥
        """
        try:
            print(f"\nğŸ” ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: '{user_query}'")
            
            # 1ë‹¨ê³„: Graph-RAG ê²€ìƒ‰
            print("ğŸ“Š 1ë‹¨ê³„: Graph-RAG ê²€ìƒ‰ ì‹¤í–‰...")
            search_results = self.graph_searcher.search(user_query)
            
            # 2ë‹¨ê³„: LLM ì¶”ì²œ ìƒì„±
            print("ğŸ¤– 2ë‹¨ê³„: LLM ì¶”ì²œ ìƒì„±...")
            recommendation = self.llm_chain.generate_recommendation(user_query, search_results)
            
            # 3ë‹¨ê³„: ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
            self.memory.save_context(
                {"input": user_query},
                {"output": recommendation}
            )
            
            print("âœ… ì¶”ì²œ ì™„ë£Œ!")
            return recommendation
            
        except Exception as e:
            error_msg = f"âŒ ì‹œìŠ¤í…œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(error_msg)
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í–¥ìˆ˜ ì¶”ì²œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    
    def get_chat_history(self) -> str:
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        return str(self.memory.buffer)
    
    def clear_memory(self):
        """ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
        self.memory.clear()
        print("ğŸ’­ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def update_generation_settings(self, max_tokens: int = None, temperature: float = None, top_p: float = None):
        """LLM ìƒì„± ì„¤ì • ì—…ë°ì´íŠ¸"""
        if max_tokens is not None:
            self.llm_chain.max_tokens = max_tokens
            print(f"âœ… max_tokens ì„¤ì •: {max_tokens}")
        
        if temperature is not None:
            self.llm_chain.temperature = temperature
            print(f"âœ… temperature ì„¤ì •: {temperature}")
        
        if top_p is not None:
            self.llm_chain.top_p = top_p
            print(f"âœ… top_p ì„¤ì •: {top_p}")

    def get_generation_settings(self) -> dict:
        """í˜„ì¬ LLM ìƒì„± ì„¤ì • ì¡°íšŒ"""
        return {
            "max_tokens": self.llm_chain.max_tokens,
            "temperature": self.llm_chain.temperature,
            "top_p": self.llm_chain.top_p
        }

    def test_connection(self) -> bool:
        """ì‹œìŠ¤í…œ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        return self.graph_searcher.test_connection()
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("ğŸ§¹ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        if hasattr(self, 'graph_searcher'):
            self.graph_searcher.close()
        print("âœ… ì •ë¦¬ ì™„ë£Œ!")


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_langchain_graph_rag():
    """LangChain Graph-RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª LangChain Graph-RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = LangChainGraphRAG()
    
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    if not rag.test_connection():
        print("âŒ Neo4j ì—°ê²° ì‹¤íŒ¨")
        return
    
    # ìƒ˜í”Œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
    test_queries = [
        "ìƒ¤ë„¬ì˜ ì—¬ì í”Œë¡œëŸ´ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜",
        "ìš°ë”” ê³„ì—´ì˜ ë‚¨ì„± í–¥ìˆ˜ ë­ê°€ ì¢‹ì•„?",
        "ë°”ë‹ë¼í–¥ê³¼ ê½ƒí–¥ì´ ë‚˜ëŠ” í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜"
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {query}")
        print('='*60)
        
        response = rag.ask(query)
        print(f"ğŸ¤– ì¶”ì²œ ê²°ê³¼:\n{response}")
    
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    rag.cleanup()
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


# ë³„ì¹­ ì •ì˜ (ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´)
PerfumeRecommendationSystem = LangChainGraphRAG

if __name__ == "__main__":
    test_langchain_graph_rag() 